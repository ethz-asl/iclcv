Briefly said, \textbf{the ICL is a C++ computer vision library}. During design and development, two main design goals took center stage: \small{\textbf{i)}} Optimal Performance and \small{\textbf{ii)}} Simple and easy to use interfaces.
\section{Optimal Performance} 
Computer vision is one of the subjects, where even processing power of modern multi-core CPU's can easily be exhausted. Therefore we decided to provide data interfaces that allow to implement algorithms as efficient as possible. In this context, three main aspects have to be mentioned:
\begin{enumerate}
\item \textbf{Providing the possibility of shallow data copies:}\\
When image data is obtained by other algorithms, modules or libraries, it must be possible to use this data (generally passed via pointers) directly without having to copy it deeply. Unfortunately there are two paradigms of storing and handling image data: \small{\textbf{i)}} Interleaved (here, several image channels are mixed and usually image data is allocated as a single data block; RGB image data is stored in RGBRGBRGB... manner) \small{\textbf{ii)}} Planar (where each channel is stored within an extra data block).\\
Of course, providing an image structure that is capable of working with both data formats natively would allow optimal performance. Unfortunately this would entail a large extra effort. Hence we decided to support only planar data layout supplemented with some very efficient conversion functions (\inlinecode{planarToInterleaved} and \inlinecode{interleavedToPlanar}).
\item \textbf{Providing low-level data access:}\\
In contrast to the aspect above, we also provide low level data access to allow to pass ICL-image data to foreign algorithms shallowly (if these algorithms are able to work with interleaved data -- Otherwise the \inlinecode{planarToInterleaved}-function will become very helpful).
\item \textbf{Native but optional support for SIMD instruction sets:}\\
SIMD (Single Instruction Mutltiple Data) Instructions, partitioned in so called \emph{processor instruction sets} (e.g. MMX, SSE1-4, AltiVec or 3DNow!) provide the possibility to apply a CPU-operation on a set of data elements simultaneously in a single CPU cycle. Therefore data processing speed can be enhanced significantly when SIMD instructions are used. In contrast, not all processors provide these instruction sets and usage is a bit inconvenient.\\
Fortunately Intel provides a so called \emph{performance library} called \textbf{Intel-IPP}\footnote{Intel-IPP is proprietary Software, but it can be used and downloaded  for free as long as software produces with it shall not be sold (see \hrefn{http://www.intel.com/cd/software/products/asmo-na/eng/340679.htm}).} (Intel performance primitives) that wraps most of the necessary SIMD instructions with an (more\footnote{Usage is still a bit complicated, but of course much better than using MMX/SSE instructions directly}) easy to use C-interface. Furthermore, algorithms implemented in the IPP make heavily use of multi-core optimization, so performance of even an optimized pure-C++ implementation is sometimes magnitudes away.\\
The Core of our ICL is implemented as a wrapper of the Intel-IPP, however IPP remains purely optional. This was achieved by providing C++-fallback implementations for (nearly\footnote{\emph{Nearly} means here, that there are some very special IPP-algorithms that were too hard to implement. Hence very few functionalities/classes/functions are not available if ICL is built without IPP support.}) all IPP-functions used. \\
Here is a short example of the IPP-Performance. Once I tried to find a good implementation of so called \inlinecode{Details in section \ref{sec:img-iterator}}. Once an implementation was found, I had to create some benchmark task for comparison of the iterator class with a simple pointer (which can also be used as an iterator): The task was to find the minimum (byte-)pixel value of an $1000\times{}1000$-pixel gray image. After some optimizations, I was able to reach the performance of the highly optimized \inlinecode{std::min\_element} algorithm when compiling with compiler flags \inlinecode{-O4 -march=native -funroll-loops}. Finding the mininum element lasted about $2$ms (which is pretty fast). However, the corresponding IPP implementation was still about \textbf{20 times} faster.
\end{enumerate}

\section{Simple, easy to use and object orientated interfaces:}
Object-orientated programming (OOP) in C++ provides both, high performance due to processor-close programming as well as a high abstraction level due to features of object orientation. In particular, (multiple) inheritance and data/function encapsulation as well as function- and class-\emph{templating} must be mentioned here. In contrast to e.g. the well known open computer vision library \emph{OpenCV} we use C++ and therewith we are able to provide a powerful image class named \inlinecode{Img}. To support different data types for image pixels (e.g. one needs byte-pixel-values as well as float-pixel values) without have in large amount of duplicated source code, we implemented \inlinecode{Img} as a template class.\\
Furthermore most other functionalities are implemented in a object orientated manner. For example, one can instantiate  \inlinecode{FileGrabber}-, \inlinecode{Filter}- or \inlinecode{Converter}-Objects that provide easy-to-use interfaces to \emph{grab} that next image, to apply a filter on an image or to convert am image.\\
To optimize performance, most image-manipulating functions are implemented in \emph{source-destination}-fashion: E.g. a Filter-instance\footnote{As elucidated later on, the set of image filters is split into \emph{unary}- and \emph{binary} operators (base classes: \inlinecode{UnaryOp} and \inlinecode{BinaryOp})} offers an \inlinecode{apply}-function, that expects a source- as well as a destination-image as arguments, where the ...  

\section{A Question of Granularity}
When developing a computer-vision library, one has made a decision over the complexity it's components. ICL provides \emph{building blocks} for the development of computer vision applications, but it does not provide high-level components like face trackers or object-detectors. Rather it supports low- and medium level structures and a large set of (highly optimised) basic algorithms.


\section{Large variety of simple-to-use Algorithms}

\section{Well-chosen selection of ready-to-use Tools}

\section{} 